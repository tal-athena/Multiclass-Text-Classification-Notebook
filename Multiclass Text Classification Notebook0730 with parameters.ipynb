{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\BinaryClassifier35\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "#Loading additional helper functions not shown here but provided in the folder\n",
    "%run nlp_utils_news.ipynb\n",
    "\n",
    "'''Features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "'''Plotting'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "'''Display'''\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "'''Sqlite'''\n",
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the Parameter JSON Data into parameter\n",
    "\n",
    "# Open json file file: file\n",
    "file = open('parameters.json',mode='r')\n",
    "json_string = file.read()\n",
    "file.close()\n",
    "\n",
    "parameter = json.loads(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "      <td>SciTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "      <td>SciTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "      <td>SciTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "      <td>SciTech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content     label\n",
       "0  Unions representing workers at Turner   Newall...  Business\n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...   SciTech\n",
       "2  AP - A company founded by a chemistry research...   SciTech\n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...   SciTech\n",
       "4  AP - Southern California's smog-fighting agenc...   SciTech"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data from sqlite file to df\n",
    "\n",
    "sqlite_file_name = \"train1.sqlite3\"\n",
    "conn = sqlite3.connect(sqlite_file_name)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT [NOTE_TEXT], [GROUP] from Documents\")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    data.append({\"note_text\": row[0], \"group\": row[1]})\n",
    "\n",
    "content, label, unique_categories = [], [], []\n",
    "for each in data:\n",
    "    content.append(each['note_text'])\n",
    "    label.append(each['group'])\n",
    "    if each['group'] not in unique_categories:\n",
    "        unique_categories.append(each['group'])\n",
    "    \n",
    "df = pd.DataFrame([content, label]).T\n",
    "df.columns= ['content', 'label']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[union, represent, worker, turner, newall, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[space.com, toronto, canada, second\\team, rock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[company, chemistry, researcher, university, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[barely, dawn, mike, fitzpatrick, start, shift...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[southern, california, smog, fight, agency, em...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content     label  \\\n",
       "0  Unions representing workers at Turner   Newall...  Business   \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...   SciTech   \n",
       "2  AP - A company founded by a chemistry research...   SciTech   \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...   SciTech   \n",
       "4  AP - Southern California's smog-fighting agenc...   SciTech   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [union, represent, worker, turner, newall, dis...  \n",
       "1  [space.com, toronto, canada, second\\team, rock...  \n",
       "2  [company, chemistry, researcher, university, l...  \n",
       "3  [barely, dawn, mike, fitzpatrick, start, shift...  \n",
       "4  [southern, california, smog, fight, agency, em...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply the function to preprocess the text. Tokenize, lower, expand contactions, lemmatize, remove punctuation, numbers and stop words\n",
    "\n",
    "df['clean_text'] = df['content'].apply(process_text_unigram)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_bi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[union, represent, worker, turner, newall, dis...</td>\n",
       "      <td>[(union, represent), (represent, worker), (wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[space.com, toronto, canada, second\\team, rock...</td>\n",
       "      <td>[(space.com, toronto), (toronto, canada), (can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[company, chemistry, researcher, university, l...</td>\n",
       "      <td>[(company, chemistry), (chemistry, researcher)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[barely, dawn, mike, fitzpatrick, start, shift...</td>\n",
       "      <td>[(barely, dawn), (dawn, mike), (mike, fitzpatr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[southern, california, smog, fight, agency, em...</td>\n",
       "      <td>[(southern, california), (california, smog), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content     label  \\\n",
       "0  Unions representing workers at Turner   Newall...  Business   \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...   SciTech   \n",
       "2  AP - A company founded by a chemistry research...   SciTech   \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...   SciTech   \n",
       "4  AP - Southern California's smog-fighting agenc...   SciTech   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  [union, represent, worker, turner, newall, dis...   \n",
       "1  [space.com, toronto, canada, second\\team, rock...   \n",
       "2  [company, chemistry, researcher, university, l...   \n",
       "3  [barely, dawn, mike, fitzpatrick, start, shift...   \n",
       "4  [southern, california, smog, fight, agency, em...   \n",
       "\n",
       "                                       clean_text_bi  \n",
       "0  [(union, represent), (represent, worker), (wor...  \n",
       "1  [(space.com, toronto), (toronto, canada), (can...  \n",
       "2  [(company, chemistry), (chemistry, researcher)...  \n",
       "3  [(barely, dawn), (dawn, mike), (mike, fitzpatr...  \n",
       "4  [(southern, california), (california, smog), (...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#When includeBigrams is true\n",
    "\n",
    "#For bi-gram\n",
    "if parameter[\"includeBigrams\"] == True:\n",
    "    df['clean_text_bi'] = df['content'].apply(process_text_bigram)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_bi</th>\n",
       "      <th>clean_text_tri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "      <td>Business</td>\n",
       "      <td>[union, represent, worker, turner, newall, dis...</td>\n",
       "      <td>[(union, represent), (represent, worker), (wor...</td>\n",
       "      <td>[(union, represent, worker), (represent, worke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[space.com, toronto, canada, second\\team, rock...</td>\n",
       "      <td>[(space.com, toronto), (toronto, canada), (can...</td>\n",
       "      <td>[(space.com, toronto, canada), (toronto, canad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[company, chemistry, researcher, university, l...</td>\n",
       "      <td>[(company, chemistry), (chemistry, researcher)...</td>\n",
       "      <td>[(company, chemistry, researcher), (chemistry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[barely, dawn, mike, fitzpatrick, start, shift...</td>\n",
       "      <td>[(barely, dawn), (dawn, mike), (mike, fitzpatr...</td>\n",
       "      <td>[(barely, dawn, mike), (dawn, mike, fitzpatric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "      <td>SciTech</td>\n",
       "      <td>[southern, california, smog, fight, agency, em...</td>\n",
       "      <td>[(southern, california), (california, smog), (...</td>\n",
       "      <td>[(southern, california, smog), (california, sm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content     label  \\\n",
       "0  Unions representing workers at Turner   Newall...  Business   \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...   SciTech   \n",
       "2  AP - A company founded by a chemistry research...   SciTech   \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...   SciTech   \n",
       "4  AP - Southern California's smog-fighting agenc...   SciTech   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  [union, represent, worker, turner, newall, dis...   \n",
       "1  [space.com, toronto, canada, second\\team, rock...   \n",
       "2  [company, chemistry, researcher, university, l...   \n",
       "3  [barely, dawn, mike, fitzpatrick, start, shift...   \n",
       "4  [southern, california, smog, fight, agency, em...   \n",
       "\n",
       "                                       clean_text_bi  \\\n",
       "0  [(union, represent), (represent, worker), (wor...   \n",
       "1  [(space.com, toronto), (toronto, canada), (can...   \n",
       "2  [(company, chemistry), (chemistry, researcher)...   \n",
       "3  [(barely, dawn), (dawn, mike), (mike, fitzpatr...   \n",
       "4  [(southern, california), (california, smog), (...   \n",
       "\n",
       "                                      clean_text_tri  \n",
       "0  [(union, represent, worker), (represent, worke...  \n",
       "1  [(space.com, toronto, canada), (toronto, canad...  \n",
       "2  [(company, chemistry, researcher), (chemistry,...  \n",
       "3  [(barely, dawn, mike), (dawn, mike, fitzpatric...  \n",
       "4  [(southern, california, smog), (california, sm...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#When includeTrigrams = true\n",
    "\n",
    "#For tri-gram\n",
    "\n",
    "if parameter[\"includeTrigrams\"] == True:\n",
    "    df['clean_text_tri'] = df['content'].apply(process_text_trigram)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business</td>\n",
       "      <td>31.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SciTech</td>\n",
       "      <td>30.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>31.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>World</td>\n",
       "      <td>31.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  word_count\n",
       "0  Business       31.36\n",
       "1   SciTech       30.77\n",
       "2    Sports       31.35\n",
       "3     World       31.74"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Avg word count by category\n",
    "\n",
    "df['word_count'] = df['content'].apply(word_count)\n",
    "avg_wc = df.groupby('label').mean().reset_index()\n",
    "avg_wc[['label','word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Business    1895\n",
       "SciTech     1895\n",
       "Sports      1895\n",
       "World       1895\n",
       "Name: content, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "Business    5\n",
       "SciTech     5\n",
       "Sports      5\n",
       "World       5\n",
       "Name: content, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Business', 'SciTech', 'Sports', 'World'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Preparing the dataframes\n",
    "\n",
    "#Splitting the df into the different categories\n",
    "df_category_list = [ df.loc[df['label'] == e] for e in unique_categories ]\n",
    "\n",
    "#Holding out 5 articles from each class for prediction at the end\n",
    "df_category_holdout_list = [ e.iloc[:5] for e in df_category_list ]\n",
    "\n",
    "df_category_list = [ e.iloc[5:] for e in df_category_list ]\n",
    "\n",
    "\n",
    "#Appending the dfs back together\n",
    "df = pd.concat(df_category_list)\n",
    "df_holdout = pd.concat(df_category_holdout_list)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "LE = LabelEncoder()\n",
    "df['label_num'] = LE.fit_transform(df['label'])\n",
    "\n",
    "display(df.groupby(['label'])['content'].count())\n",
    "display(df_holdout.groupby(['label'])['content'].count())\n",
    "display(df['label'].unique())\n",
    "display(df['label_num'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7580, 20364)\n",
      "(7580,)\n"
     ]
    }
   ],
   "source": [
    "#Creating the features (tf-idf weights) for the processed text\n",
    "\n",
    "texts = df['clean_text'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts) #features\n",
    "y = df['label_num'].values #target\n",
    "\n",
    "print (X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7580, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "#When SGDClassifier is true\n",
    "\n",
    "#Hyperparameter tuning\n",
    "#Gridsearch with 5-fold cross validation\n",
    "#Warning this can take a long time!!!\n",
    "\n",
    "\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    #SGD\n",
    "    loss =  ['log']\n",
    "    penalty = ['l2','l1']\n",
    "    alpha = [1e-6, 1e-3, 1e-1, 1e0]\n",
    "    max_iter = [5, 1000, 10000]\n",
    "    tol = [None, 1e-3]\n",
    "    eta0 = [0.1, 0.001]\n",
    "\n",
    "    random_state = [3]\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "\n",
    "    params = dict(loss=loss,\n",
    "                  penalty=penalty,\n",
    "                  alpha=alpha,\n",
    "                  max_iter=max_iter,\n",
    "                  tol=tol,\n",
    "                  random_state=random_state)\n",
    "\n",
    "    gridsearch = GridSearchCV(clf,\n",
    "                              params,\n",
    "                              cv = 5,\n",
    "                              verbose = 1, \n",
    "                              n_jobs = -1)\n",
    "\n",
    "    sgd_best_model = gridsearch.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When SGDClassifier is true\n",
    "\n",
    "#Define the best models with the selected params from the grdsearch\n",
    "#Gridsearch was done on a virtual machine outisde of this notebook\n",
    "#Normally you can just say 'best_model = gridsearch.best_params_' \n",
    "#to use the best parameters from the gridsearch\n",
    "\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    sgd_best_model = SGDClassifier(alpha=1e-06,\n",
    "                                   loss='log',\n",
    "                                   max_iter=1000,\n",
    "                                   penalty='l2',\n",
    "                                   learning_rate = 'constant',\n",
    "                                   eta0 = .1,\n",
    "                                   random_state = 3,\n",
    "                                   tol=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When SGDClassifier is true\n",
    "\n",
    "#Plot AUC - SGD\n",
    "\n",
    "#Binarize the labels\n",
    "\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    y_b = label_binarize(y, classes = [0, 1, 2, 3])\n",
    "    n_classes = y_b.shape[1]\n",
    "\n",
    "    #Shuffle and split training and test sets with stratified sampling and binarized labels\n",
    "    X_train_b, X_test_b, y_train_b, y_test_b = train_test_split(X,\n",
    "                                                                y_b,\n",
    "                                                                test_size = .3,\n",
    "                                                                shuffle = True,\n",
    "                                                                stratify = y,\n",
    "                                                                random_state = 3)\n",
    "\n",
    "    #Learn to predict each class against the other\n",
    "    sgd_classifier = OneVsRestClassifier(sgd_best_model)\n",
    "\n",
    "    y_score = sgd_classifier.fit(X_train_b, y_train_b).predict_proba(X_test_b)\n",
    "\n",
    "    #Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_b[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    #Compute micro-average ROC curve and ROC area\n",
    "    fpr['micro'], tpr['micro'], _ = roc_curve(y_test_b.ravel(), y_score.ravel())\n",
    "    roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])\n",
    "\n",
    "    #First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    #Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    #Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr['macro'] = all_fpr\n",
    "    tpr['macro'] = mean_tpr\n",
    "    roc_auc['macro'] = auc(fpr['macro'], tpr['macro'])\n",
    "\n",
    "    #Plot all ROC curves\n",
    "    plt.figure(figsize=(13,10)) \n",
    "    sns.set_style('darkgrid')\n",
    "    lw=2\n",
    "\n",
    "    plt.plot(fpr['micro'], \n",
    "             tpr['micro'], \n",
    "             label='micro-average ROC curve (area = {0:0.3f})'''.format(roc_auc['micro']),\n",
    "             color='deeppink',\n",
    "             linestyle=':', \n",
    "             linewidth=4)\n",
    "\n",
    "    plt.plot(fpr['macro'], \n",
    "             tpr['macro'], \n",
    "             label='macro-average ROC curve (area = {0:0.3f})'''.format(roc_auc['macro']),\n",
    "             color='navy', \n",
    "             linestyle=':', \n",
    "             linewidth=4)\n",
    "\n",
    "    colors = cycle(['#41924F', '#FFC300', '#a98ff3', '#59C7EA'])\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], \n",
    "                 color=color, \n",
    "                 lw=lw, \n",
    "                 label='ROC curve of class {0} (area = {1:0.3f})'''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('1-Specificity (False Positive Rate)', fontsize = 14)\n",
    "    plt.ylabel('Sensitivity (True Positive Rate)', fontsize = 14)\n",
    "    plt.title('Receiver Operating Characteristic - SGD (loss = log)', fontsize = 16)\n",
    "    plt.legend(loc=\"lower right\", fontsize = 13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When SGDClassifier is true\n",
    "\n",
    "#Confusion Matrix - SGD\n",
    "#Train test split with stratified sampling. Using non-binarized labels\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size = .3, \n",
    "                                                        shuffle = True, \n",
    "                                                        stratify = y, \n",
    "                                                        random_state = 3)\n",
    "    #Fit the training data\n",
    "    sgd_best_model.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the testing data\n",
    "    y_pred = sgd_best_model.predict(X_test)\n",
    "\n",
    "    #Get the confusion matrix and put it into a df\n",
    "    cm = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index = unique_categories, \n",
    "                         columns = unique_categories)\n",
    "\n",
    "    #Plot the heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    sns.heatmap(cm_df, \n",
    "                center=0, \n",
    "                cmap=sns.diverging_palette(220, 15, as_cmap=True), \n",
    "                annot=True, \n",
    "                fmt='g')\n",
    "\n",
    "    plt.title('SGD (loss = log) \\nF1 Score (avg = macro) : {0:.2f}'.format(f1_score(y_test, y_pred, average='macro')), fontsize = 13)\n",
    "    plt.ylabel('True label', fontsize = 13)\n",
    "    plt.xlabel('Predicted label', fontsize = 13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When RandomForestClassifier parameter is true\n",
    "\n",
    "#Hyperparameter tuning\n",
    "#Gridsearch with 5-fold cross validation\n",
    "#Warning this can take a long time!!!\n",
    "\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    #RF\n",
    "    bootstrap = [True, False]\n",
    "    max_depth = [10, 50, 100, None]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    n_estimators = [800, 1400, 2000]\n",
    "    random_state = [3]\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "\n",
    "    params = dict(bootstrap = bootstrap,\n",
    "                  max_depth = max_depth,\n",
    "                  max_features = max_features,\n",
    "                  min_samples_leaf = min_samples_leaf,\n",
    "                  n_estimators = n_estimators,\n",
    "                  random_state=random_state)\n",
    "\n",
    "    gridsearch = GridSearchCV(clf,\n",
    "                              params, \n",
    "                              cv=5,\n",
    "                              verbose=1, \n",
    "                              n_jobs=-1)\n",
    "\n",
    "    rf_best_model = gridsearch.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When RandomForestClassifier is true\n",
    "\n",
    "#Define the best models with the selected params from the grdsearch\n",
    "#Gridsearch was done on a virtual machine outisde of this notebook\n",
    "#Normally you can just say 'best_model = gridsearch.best_params_' \n",
    "#to use the best parameters from the gridsearch\n",
    "\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    rf_best_model = RandomForestClassifier(bootstrap = False,\n",
    "                                           max_depth = 50,\n",
    "                                           max_features = 'auto',\n",
    "                                           min_samples_leaf = 1,\n",
    "                                           n_estimators = 1400,\n",
    "                                           random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When RandomForestClassifier parameter is true\n",
    "\n",
    "#Plot AUC - RF\n",
    "#Learn to predict each class against the other\n",
    "    \n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    \n",
    "    rf_classifier = OneVsRestClassifier(rf_best_model)\n",
    "\n",
    "    y_score = rf_classifier.fit(X_train_b, y_train_b).predict_proba(X_test_b)\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_b[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    #Compute micro-average ROC curve and ROC area\n",
    "    fpr['micro'], tpr['micro'], _ = roc_curve(y_test_b.ravel(), y_score.ravel())\n",
    "    roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])\n",
    "\n",
    "    #First aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "    #Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    #Finally average it and compute AUC\n",
    "    mean_tpr /= n_classes\n",
    "\n",
    "    fpr['macro'] = all_fpr\n",
    "    tpr['macro'] = mean_tpr\n",
    "    roc_auc['macro'] = auc(fpr['macro'], tpr['macro'])\n",
    "\n",
    "    #Plot all ROC curves\n",
    "    plt.figure(figsize=(13,10)) \n",
    "    sns.set_style('darkgrid')\n",
    "    lw=2\n",
    "\n",
    "    plt.plot(fpr['micro'], \n",
    "             tpr['micro'], \n",
    "             label='micro-average ROC curve (area = {0:0.3f})'''.format(roc_auc['micro']),\n",
    "             color='deeppink',\n",
    "             linestyle=':', \n",
    "             linewidth=4)\n",
    "\n",
    "    plt.plot(fpr['macro'], \n",
    "             tpr['macro'], \n",
    "             label='macro-average ROC curve (area = {0:0.3f})'''.format(roc_auc['macro']),\n",
    "             color='navy', \n",
    "             linestyle=':', \n",
    "             linewidth=4)\n",
    "\n",
    "    colors = cycle(['#41924F', '#FFC300', '#a98ff3', '#59C7EA'])\n",
    "\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(fpr[i], tpr[i], \n",
    "                 color=color, \n",
    "                 lw=lw, \n",
    "                 label='ROC curve of class {0} (area = {1:0.3f})'''.format(i, roc_auc[i]))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('1-Specificity (False Positive Rate)', fontsize = 14)\n",
    "    plt.ylabel('Sensitivity (True Positive Rate)', fontsize = 14)\n",
    "    plt.title('Receiver Operating Characteristic - RF', fontsize = 16)\n",
    "    plt.legend(loc=\"lower right\", fontsize = 13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#When RandomForestClassifier is true\n",
    "\n",
    "#Confusion Matrix - RF\n",
    "#Fit the training data\n",
    "\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    \n",
    "    rf_best_model.fit(X_train, y_train)\n",
    "\n",
    "    #Predict the testing data\n",
    "    y_pred = rf_best_model.predict(X_test)\n",
    "\n",
    "    #Get the confusion matrix and put it into a df\n",
    "    cm = confusion_matrix(y_test, y_pred) \n",
    "\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                         index = unique_categories, \n",
    "                         columns = unique_categories)\n",
    "\n",
    "    #Plot the heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    sns.heatmap(cm_df, \n",
    "                center=0, \n",
    "                cmap=sns.diverging_palette(220, 15, as_cmap=True), \n",
    "                annot=True, \n",
    "                fmt='g')\n",
    "\n",
    "    plt.title('Random Forest \\nF1 Score (avg = macro) : {0:.2f}'.format(f1_score(y_test, y_pred, average='macro')), fontsize = 13)\n",
    "    plt.ylabel('True label', fontsize = 13)\n",
    "    plt.xlabel('Predicted label', fontsize = 13)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting it all together to make predictions on the unseen text\n",
    "\n",
    "#Get the text of the 5 articles we held out from each of the categories in the beginning\n",
    "unseen = df_holdout['clean_text'].astype('str') \n",
    "\n",
    "#Use the saved models to transform the unseen text with tf-idf and lsa\n",
    "X_unseen_tfidf = tfidf_vectorizer.transform(unseen) \n",
    "X_unseen = lsa.transform(X_unseen_tfidf)\n",
    "\n",
    "#Fit the models with the best params on the full data\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    sgd_best_model.fit(X, y)\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    rf_best_model.fit(X, y)\n",
    "\n",
    "#Make the prediction on the unseen articles with the fitted best models and put it into a df alongside the correct labels\n",
    "\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    df_holdout['pred_sgd'] = sgd_best_model.predict(X_unseen)\n",
    "\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    df_holdout['pred_rf'] = rf_best_model.predict(X_unseen)\n",
    "\n",
    "label_num_dict = {}\n",
    "for i in range(0, len(unique_categories)):\n",
    "    label_num_dict[unique_categories[i]] = i\n",
    "\n",
    "df_holdout['correct'] = df_holdout['label'].map(label_num_dict)\n",
    "df_holdout = df_holdout.drop('clean_text', 1)\n",
    "\n",
    "\n",
    "columns = ['content', 'label']\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    columns.append('pred_sgd')\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    columns.append('pred_rf')\n",
    "\n",
    "columns.append('correct')\n",
    "\n",
    "df_holdout = df_holdout[columns]\n",
    "\n",
    "df_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the original full unsampled dataset for predictions\n",
    "\n",
    "conn = sqlite3.connect(\"train.sqlite3\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT [NOTE_TEXT], [GROUP] from Documents\")\n",
    "\n",
    "rows = cur.fetchall()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "data = []\n",
    "for row in rows:\n",
    "    data.append({\"note_text\": row[0], \"group\": row[1]})\n",
    "\n",
    "content, label = [], []\n",
    "for each in data:\n",
    "    content.append(each['note_text'])\n",
    "    label.append(each['group'])\n",
    "    if each['group'] not in unique_categories:\n",
    "        unique_categories.append(each['group'])\n",
    "        \n",
    "df = pd.DataFrame([content, label]).T\n",
    "df.columns= ['content', 'label']\n",
    "\n",
    "#Splitting the df into different categoreis\n",
    "df_category_list = [ df.loc[df['label'] == e] for e in unique_categories ]\n",
    "\n",
    "#Holding out 5 articles from each class for prediction at the end\n",
    "df_category_holdout_list = [ e.iloc[:5] for e in df_category_list]\n",
    "\n",
    "df_category_list = [ e.iloc[5:] for e in df_category_list]\n",
    "\n",
    "\n",
    "#Appending the dfs back together\n",
    "df = pd.concat(df_category_list)\n",
    "df_holdout = pd.concat(df_category_holdout_list)\n",
    "\n",
    "df['clean_text'] = df['content'].apply(process_text_unigram) \n",
    "\n",
    "#Turning the labels into numbers\n",
    "LE = LabelEncoder()\n",
    "df['label_num'] = LE.fit_transform(df['label'])\n",
    "\n",
    "#Get the text of the 5 articles we held out from each of the categories in the beginning\n",
    "df_holdout['clean_text'] = df_holdout['content'].apply(process_text_unigram) \n",
    "unseen = df_holdout['clean_text'].astype('str') \n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['clean_text'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts) #features\n",
    "y = df['label_num'].values #target\n",
    "\n",
    "#Dimenionality reduction. Only using the 100 best features\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "\n",
    "#Use the saved models to transform the unseen text with tf-idf and lsa\n",
    "X_unseen_tfidf = tfidf_vectorizer.transform(unseen) \n",
    "X_unseen = lsa.transform(X_unseen_tfidf)\n",
    "\n",
    "#Fit the models with the best params on the full data\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    sgd_best_model.fit(X, y)\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    rf_best_model.fit(X, y)\n",
    "\n",
    "#Make the prediction on the unseen articles with the fitted best models and put it into a df alongside the correct labels\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    df_holdout['pred_sgd'] = sgd_best_model.predict(X_unseen)\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    df_holdout['pred_rf'] = rf_best_model.predict(X_unseen)\n",
    "\n",
    "label_num_dict = {}\n",
    "for i in range(0, len(unique_categories)):\n",
    "    label_num_dict[unique_categories[i]] = i\n",
    "\n",
    "df_holdout['correct'] = df_holdout['label'].map(label_num_dict)\n",
    "df_holdout = df_holdout.drop('clean_text', 1)\n",
    "\n",
    "\n",
    "columns = ['content', 'label']\n",
    "if parameter[\"SGDClassifier\"] == True:\n",
    "    columns.append('pred_sgd')\n",
    "if parameter[\"RandomForestClassifier\"] == True:\n",
    "    columns.append('pred_rf')\n",
    "\n",
    "columns.append('correct')\n",
    "\n",
    "df_holdout = df_holdout[columns]\n",
    "\n",
    "df_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
